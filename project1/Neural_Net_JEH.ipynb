{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import OrderedDict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed random number generation\n",
    "torch.manual_seed(62)\n",
    "np.random.seed(62)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net Model\n",
    "### Fake Deep - CMS 155\n",
    "I will first import the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>DISCOVERY_TIME</th>\n",
       "      <th>FIRE_SIZE</th>\n",
       "      <th>FIPS_NAME</th>\n",
       "      <th>FIPS_CODE</th>\n",
       "      <th>SOURCE_REPORTING_UNIT_NAME</th>\n",
       "      <th>DATE</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>38.205000</td>\n",
       "      <td>-120.335000</td>\n",
       "      <td>0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>33.813100</td>\n",
       "      <td>-85.104300</td>\n",
       "      <td>1</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>82</td>\n",
       "      <td>143.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>32.201000</td>\n",
       "      <td>-82.498700</td>\n",
       "      <td>1</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>130</td>\n",
       "      <td>209.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>32.509300</td>\n",
       "      <td>-81.708600</td>\n",
       "      <td>1</td>\n",
       "      <td>1215.0</td>\n",
       "      <td>4.40</td>\n",
       "      <td>19</td>\n",
       "      <td>31.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>33.663889</td>\n",
       "      <td>-116.171944</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   LATITUDE   LONGITUDE  STATE  DISCOVERY_TIME  FIRE_SIZE  FIPS_NAME  \\\n",
       "0   0  38.205000 -120.335000      0           130.0       0.10        215   \n",
       "1   1  33.813100  -85.104300      1          1115.0       1.17         82   \n",
       "2   2  32.201000  -82.498700      1          1600.0       0.07        130   \n",
       "3   3  32.509300  -81.708600      1          1215.0       4.40         19   \n",
       "4   4  33.663889 -116.171944      0             0.0       0.20        215   \n",
       "\n",
       "   FIPS_CODE  SOURCE_REPORTING_UNIT_NAME  DATE  LABEL  \n",
       "0        0.0                         157     0      1  \n",
       "1      143.0                          71     0      4  \n",
       "2      209.0                          71     0      2  \n",
       "3       31.0                          71     0      4  \n",
       "4        0.0                          14     0      2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./datasets/jeh_train_label-enc_iter-imp_linear-norm.csv\")\n",
    "# Rather than do real imputation,I just replace nans with zeros\n",
    "df_train = df_train.fillna(0)\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>DISCOVERY_TIME</th>\n",
       "      <th>FIRE_SIZE</th>\n",
       "      <th>FIPS_NAME</th>\n",
       "      <th>FIPS_CODE</th>\n",
       "      <th>SOURCE_REPORTING_UNIT_NAME</th>\n",
       "      <th>DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>285382</td>\n",
       "      <td>34.346944</td>\n",
       "      <td>-117.442222</td>\n",
       "      <td>0</td>\n",
       "      <td>1605.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>158</td>\n",
       "      <td>71.0</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>285383</td>\n",
       "      <td>34.020390</td>\n",
       "      <td>-116.179970</td>\n",
       "      <td>0</td>\n",
       "      <td>1545.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>285384</td>\n",
       "      <td>38.068611</td>\n",
       "      <td>-120.276667</td>\n",
       "      <td>0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>196</td>\n",
       "      <td>109.0</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>285385</td>\n",
       "      <td>32.499971</td>\n",
       "      <td>-83.742573</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>87</td>\n",
       "      <td>153.0</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>285386</td>\n",
       "      <td>32.924940</td>\n",
       "      <td>-114.992530</td>\n",
       "      <td>0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>89</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   LATITUDE   LONGITUDE  STATE  DISCOVERY_TIME  FIRE_SIZE  FIPS_NAME  \\\n",
       "0  285382  34.346944 -117.442222      0          1605.0        0.2        158   \n",
       "1  285383  34.020390 -116.179970      0          1545.0        0.1        218   \n",
       "2  285384  38.068611 -120.276667      0          1200.0        0.1        196   \n",
       "3  285385  32.499971  -83.742573      1             0.0        0.4         87   \n",
       "4  285386  32.924940 -114.992530      0           126.0        0.1         89   \n",
       "\n",
       "   FIPS_CODE  SOURCE_REPORTING_UNIT_NAME  DATE  \n",
       "0       71.0                         145     0  \n",
       "1        0.0                          69     0  \n",
       "2      109.0                         170     0  \n",
       "3      153.0                          47     1  \n",
       "4       25.0                          18     1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"./datasets/jeh_test_label-enc_iter-imp_linear-norm.csv\")\n",
    "df_test = df_test.fillna(0)\n",
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I separate the data randomly into training and testing sets, with a 75/25 split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = len(df_train.columns[1:-1])\n",
    "N_total = len(df_train)\n",
    "N = int(0.75 * N_total)\n",
    "N_test = N_total - N\n",
    "test_indices = np.random.choice(list(range(N_total)), size=N_test, replace=False)\n",
    "X_predict = df_test.to_numpy(dtype = float)[:, 1:]\n",
    "X_train = np.zeros([N, D], dtype = float)\n",
    "Y_train = np.zeros(N, dtype = int)\n",
    "X_test = np.zeros([N_test, D], dtype = float)\n",
    "Y_test = np.zeros(N_test, dtype = int)\n",
    "j = 0\n",
    "k = 0\n",
    "for i in range(len(df_train)):\n",
    "    if i not in test_indices:\n",
    "        X_train[j, :] = df_train.iloc[i, 1:-1]\n",
    "        Y_train[j] = df_train.iloc[i, -1]\n",
    "        j += 1\n",
    "    else:\n",
    "        X_test[k, :] = df_train.iloc[i, 1:-1]\n",
    "        Y_test[k] = df_train.iloc[i, -1]\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will apply a basic normalization to each column. I am careful to normalize everything using only the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(D):\n",
    "    mu = np.mean(X_train[:, i])\n",
    "    stddev = np.std(X_train[:, i])\n",
    "    X_train[:, i] = (X_train[:, i] - mu ) / stddev\n",
    "    X_test[:, i] = (X_test[:, i] - mu ) / stddev\n",
    "    X_predict[:, i] = (X_predict[:, i] - mu ) / stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We require Y_train and Y_test to be from 0-3, not 1-4\n",
    "Y_train = Y_train - 1\n",
    "Y_test = Y_test - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I actually need to onehot encode the labels to the data set. In effect, my neural net will have 4 output units and I want the labels to emulate this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = len(np.unique(Y_train))\n",
    "Y_train_oh = np.zeros([len(Y_train), C])\n",
    "Y_test_oh = np.zeros([len(Y_test), C])\n",
    "for i in range(len(Y_train)):\n",
    "    y = Y_train[i] - 1\n",
    "    Y_train_oh[i, y] = 1\n",
    "for i in range(len(Y_test)):\n",
    "    y = Y_test[i] - 1\n",
    "    Y_test_oh[i, y] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to write a dataset class in order to use this set with pytorch. This is totally barebones, but I don't need to worry about streaming the dataset off the hard drive to multiple cores, since I have the memory to just store the entire dataset on each core. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \"Dataset object for pytorch.\"\n",
    "    def __init__(self, X, Y):\n",
    "        'Initialization'\n",
    "        self.Y = Y.astype(float)\n",
    "        self.X = X.astype(float)\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.Y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Load data and get label\n",
    "        x = self.X[index]\n",
    "        y = self.Y[index]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this class to actually construct dataset objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(X_train, Y_train_oh)\n",
    "test_dataset = Dataset(X_test, Y_test_oh)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1024, shuffle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use my GPU to try and speed up the neural net. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# device = torch.device('cpu')\n",
    "# When you are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll take a first stab at the model architecture. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(D, 100),\n",
    "    nn.Linear(100, 500),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(500, 500),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(500, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(100, C),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=float(1e-4))\n",
    "loss_fn = nn.SmoothL1Loss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will import some helper functions that I wrote in problem set 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(12):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # Erase accumulated gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(data.float())\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = loss_fn(output, target.float())\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Weight update\n",
    "            optimizer.step()\n",
    "\n",
    "        # Track loss each epoch\n",
    "        print('Train Epoch: %d  Loss: %.4f' % (epoch + 1,  loss.item()))\n",
    "\n",
    "def get_train_err():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    train_error = 0\n",
    "    train_loss = 0\n",
    "    # Turning off automatic differentiation\n",
    "    with torch.no_grad():\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data.float())\n",
    "            train_loss += loss_fn(output, target).item() * len(target) # Sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=False).cpu().numpy()  # Get the index of the max class score\n",
    "            \n",
    "            # Convert the target back from onehot encoding\n",
    "            target = target.cpu().numpy()\n",
    "            target = target[:, 1] + target[:, 2] * 2 + target[:, 3] * 3\n",
    "            \n",
    "            # Determine the accuracy of the classification\n",
    "            correct += np.sum(pred==target)\n",
    "            train_error += roc_auc_score(target, \n",
    "                                         output.cpu(), \n",
    "                                         multi_class='ovr') * len(target)\n",
    "            \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_error /= len(train_loader.dataset)\n",
    "    print(\"Average Training ROC AUC: %.3f\"%train_error)\n",
    "    print('Training set: Average loss: %.4f, Accuracy: %d/%d (%.4f)' %\n",
    "          (train_loss, correct, len(train_loader.dataset),\n",
    "           100. * correct / len(train_loader.dataset)))\n",
    "    \n",
    "def get_test_err():\n",
    "    # Putting layers like Dropout into evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    test_error = 0\n",
    "\n",
    "    # Turning off automatic differentiation\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data.float())\n",
    "            test_loss += loss_fn(output, target).item() * len(target)  # Sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=False).cpu().numpy()  # Get the index of the max class score\n",
    "            \n",
    "            # Convert the target back from onehot encoding\n",
    "            target = target.cpu().numpy()\n",
    "            target = target[:, 1] + target[:, 2] * 2 + target[:, 3] * 3\n",
    "            \n",
    "            # Determine the accuracy of the classification\n",
    "            correct += np.sum(pred==target)\n",
    "            test_error += roc_auc_score(target, \n",
    "                                        output.cpu(), \n",
    "                                        multi_class='ovr') * len(target)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_error /= len(test_loader.dataset)\n",
    "    print(\"Average Testing ROC AUC: %.3f\"%test_error)\n",
    "    print('Test set: Average loss: %.4f, Accuracy: %d/%d (%.4f)' %\n",
    "          (test_loss, correct, len(test_loader.dataset),\n",
    "           100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "train_model()\n",
    "get_train_err()\n",
    "get_test_err()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now try constructing and testing an **even deeper** neural net. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (start): Linear(in_features=9, out_features=100, bias=True)\n",
      "  (expand1): Linear(in_features=100, out_features=5000, bias=True)\n",
      "  (expand2): ReLU()\n",
      "  (expand3): Dropout(p=0.05, inplace=False)\n",
      "  (1-0): Linear(in_features=5000, out_features=5000, bias=True)\n",
      "  (2-0): ReLU()\n",
      "  (3-0): Dropout(p=0.05, inplace=False)\n",
      "  (1-1): Linear(in_features=5000, out_features=5000, bias=True)\n",
      "  (2-1): ReLU()\n",
      "  (3-1): Dropout(p=0.05, inplace=False)\n",
      "  (1-2): Linear(in_features=5000, out_features=5000, bias=True)\n",
      "  (2-2): ReLU()\n",
      "  (3-2): Dropout(p=0.05, inplace=False)\n",
      "  (1-3): Linear(in_features=5000, out_features=5000, bias=True)\n",
      "  (2-3): ReLU()\n",
      "  (3-3): Dropout(p=0.05, inplace=False)\n",
      "  (narrow1): Linear(in_features=5000, out_features=100, bias=True)\n",
      "  (narrow2): ReLU()\n",
      "  (narrow3): Dropout(p=0.05, inplace=False)\n",
      "  (final-1): Linear(in_features=100, out_features=4, bias=True)\n",
      "  (final-2): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "height = 5000\n",
    "narrow = 100\n",
    "drop = 0.05\n",
    "depth = 4\n",
    "ordict = OrderedDict()\n",
    "ordict['start'] = nn.Linear(D, narrow)\n",
    "ordict['expand1'] = nn.Linear(narrow, height)\n",
    "ordict['expand2'] = nn.ReLU()\n",
    "ordict['expand3'] = nn.Dropout(drop)\n",
    "\n",
    "# Construct the bulk of the net\n",
    "for i in range(depth):\n",
    "    ordict['1-%i'%i] = nn.Linear(height, height)\n",
    "    ordict['2-%i'%i] = nn.ReLU()\n",
    "    ordict['3-%i'%i] = nn.Dropout(drop)\n",
    "    \n",
    "# Narrow the net and bring it down to the last few nodes\n",
    "ordict['narrow1'] = nn.Linear(height, narrow)\n",
    "ordict['narrow2'] = nn.ReLU()\n",
    "ordict['narrow3'] = nn.Dropout(drop)\n",
    "ordict['final-1'] = nn.Linear(narrow, C)\n",
    "ordict['final-2'] = nn.Softmax(dim=1)\n",
    "\n",
    "# Pack all the layers into the model\n",
    "model = nn.Sequential(ordict)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=float(1e-4))\n",
    "loss_fn = nn.SmoothL1Loss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1  Loss: 0.0753\n",
      "Train Epoch: 2  Loss: 0.0715\n",
      "Train Epoch: 3  Loss: 0.0641\n",
      "Train Epoch: 4  Loss: 0.0839\n",
      "Train Epoch: 5  Loss: 0.0557\n",
      "Train Epoch: 6  Loss: 0.0507\n",
      "Train Epoch: 7  Loss: 0.0516\n",
      "Train Epoch: 8  Loss: 0.0477\n",
      "Train Epoch: 9  Loss: 0.0585\n",
      "Train Epoch: 10  Loss: 0.0474\n",
      "Train Epoch: 11  Loss: 0.0631\n",
      "Train Epoch: 12  Loss: 0.0654\n",
      "Average Training ROC AUC: 0.783\n",
      "Training set: Average loss: 0.0620, Accuracy: 136162/214036 (63.6164)\n",
      "Average Testing ROC AUC: 0.782\n",
      "Test set: Average loss: 0.0622, Accuracy: 45215/71346 (63.3743)\n"
     ]
    }
   ],
   "source": [
    "train_model()\n",
    "get_train_err()\n",
    "get_test_err()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model looks good. Let's train it on everything. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1  Loss: 0.0622\n",
      "Train Epoch: 2  Loss: 0.0656\n",
      "Train Epoch: 3  Loss: 0.0586\n",
      "Train Epoch: 4  Loss: 0.0631\n",
      "Train Epoch: 5  Loss: 0.0630\n",
      "Train Epoch: 6  Loss: 0.0575\n",
      "Train Epoch: 7  Loss: 0.0648\n",
      "Train Epoch: 8  Loss: 0.0609\n",
      "Train Epoch: 9  Loss: 0.0628\n",
      "Train Epoch: 10  Loss: 0.0578\n",
      "Train Epoch: 11  Loss: 0.0617\n",
      "Train Epoch: 12  Loss: 0.0624\n",
      "Average Training ROC AUC: 0.802\n",
      "Training set: Average loss: 0.0599, Accuracy: 185233/285382 (64.9070)\n"
     ]
    }
   ],
   "source": [
    "Y_oh = np.zeros([N_total, C])\n",
    "X = np.zeros([N_total, D])\n",
    "Y_oh[:N, :] = Y_train_oh\n",
    "Y_oh[N:, :] = Y_test_oh\n",
    "X[:N, :] = X_train\n",
    "X[N:, :] = X_test\n",
    "train_dataset = Dataset(X, Y_oh)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "\n",
    "# Redefine the model\n",
    "model = nn.Sequential(ordict)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=float(1e-4))\n",
    "loss_fn = nn.SmoothL1Loss()\n",
    "\n",
    "# Retrain the model on all avaliable data and get the training error. \n",
    "train_model()\n",
    "get_train_err()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is well trained, I will predict the labels and submit to kaggle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred_data = np.zeros([len(X_predict), 5])\n",
    "with torch.no_grad():\n",
    "    pred_data[:, 1:] = model(torch.tensor(X_predict).to(device).float()).cpu()\n",
    "pred_data[:, 0] = df_test[\"id\"].values\n",
    "pred_df = pd.DataFrame(pred_data, columns = [\"id\", \"P1\", \"P2\", \"P3\", \"P4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pred_df.astype({'id': 'int'})\n",
    "pred_df.to_csv(\"./FakeDeep_Attempt4_NeuralNet.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_predict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>285382</td>\n",
       "      <td>0.508899</td>\n",
       "      <td>0.160748</td>\n",
       "      <td>0.289178</td>\n",
       "      <td>0.041175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>285383</td>\n",
       "      <td>0.322410</td>\n",
       "      <td>0.013904</td>\n",
       "      <td>0.094937</td>\n",
       "      <td>0.568750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>285384</td>\n",
       "      <td>0.419784</td>\n",
       "      <td>0.233136</td>\n",
       "      <td>0.227026</td>\n",
       "      <td>0.120054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>285385</td>\n",
       "      <td>0.287099</td>\n",
       "      <td>0.516503</td>\n",
       "      <td>0.118180</td>\n",
       "      <td>0.078218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>285386</td>\n",
       "      <td>0.377663</td>\n",
       "      <td>0.224787</td>\n",
       "      <td>0.331835</td>\n",
       "      <td>0.065715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73030</th>\n",
       "      <td>358412</td>\n",
       "      <td>0.861071</td>\n",
       "      <td>0.081721</td>\n",
       "      <td>0.041671</td>\n",
       "      <td>0.015536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73031</th>\n",
       "      <td>358413</td>\n",
       "      <td>0.335623</td>\n",
       "      <td>0.069149</td>\n",
       "      <td>0.587107</td>\n",
       "      <td>0.008120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73032</th>\n",
       "      <td>358414</td>\n",
       "      <td>0.604119</td>\n",
       "      <td>0.100185</td>\n",
       "      <td>0.287817</td>\n",
       "      <td>0.007879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73033</th>\n",
       "      <td>358415</td>\n",
       "      <td>0.573586</td>\n",
       "      <td>0.106984</td>\n",
       "      <td>0.297592</td>\n",
       "      <td>0.021839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73034</th>\n",
       "      <td>358416</td>\n",
       "      <td>0.364558</td>\n",
       "      <td>0.148368</td>\n",
       "      <td>0.343405</td>\n",
       "      <td>0.143669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73035 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        P1        P2        P3        P4\n",
       "0      285382  0.508899  0.160748  0.289178  0.041175\n",
       "1      285383  0.322410  0.013904  0.094937  0.568750\n",
       "2      285384  0.419784  0.233136  0.227026  0.120054\n",
       "3      285385  0.287099  0.516503  0.118180  0.078218\n",
       "4      285386  0.377663  0.224787  0.331835  0.065715\n",
       "...       ...       ...       ...       ...       ...\n",
       "73030  358412  0.861071  0.081721  0.041671  0.015536\n",
       "73031  358413  0.335623  0.069149  0.587107  0.008120\n",
       "73032  358414  0.604119  0.100185  0.287817  0.007879\n",
       "73033  358415  0.573586  0.106984  0.297592  0.021839\n",
       "73034  358416  0.364558  0.148368  0.343405  0.143669\n",
       "\n",
       "[73035 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./FakeDeep_Attempt4_NeuralNet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>285382</td>\n",
       "      <td>0.508899</td>\n",
       "      <td>0.160748</td>\n",
       "      <td>0.289178</td>\n",
       "      <td>0.041175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>285383</td>\n",
       "      <td>0.322410</td>\n",
       "      <td>0.013904</td>\n",
       "      <td>0.094937</td>\n",
       "      <td>0.568750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>285384</td>\n",
       "      <td>0.419784</td>\n",
       "      <td>0.233136</td>\n",
       "      <td>0.227026</td>\n",
       "      <td>0.120054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>285385</td>\n",
       "      <td>0.287099</td>\n",
       "      <td>0.516503</td>\n",
       "      <td>0.118180</td>\n",
       "      <td>0.078218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>285386</td>\n",
       "      <td>0.377663</td>\n",
       "      <td>0.224787</td>\n",
       "      <td>0.331835</td>\n",
       "      <td>0.065715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73030</th>\n",
       "      <td>358412</td>\n",
       "      <td>0.861071</td>\n",
       "      <td>0.081721</td>\n",
       "      <td>0.041671</td>\n",
       "      <td>0.015536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73031</th>\n",
       "      <td>358413</td>\n",
       "      <td>0.335623</td>\n",
       "      <td>0.069149</td>\n",
       "      <td>0.587107</td>\n",
       "      <td>0.008120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73032</th>\n",
       "      <td>358414</td>\n",
       "      <td>0.604119</td>\n",
       "      <td>0.100185</td>\n",
       "      <td>0.287817</td>\n",
       "      <td>0.007879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73033</th>\n",
       "      <td>358415</td>\n",
       "      <td>0.573586</td>\n",
       "      <td>0.106984</td>\n",
       "      <td>0.297592</td>\n",
       "      <td>0.021839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73034</th>\n",
       "      <td>358416</td>\n",
       "      <td>0.364558</td>\n",
       "      <td>0.148368</td>\n",
       "      <td>0.343405</td>\n",
       "      <td>0.143669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73035 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        P1        P2        P3        P4\n",
       "0      285382  0.508899  0.160748  0.289178  0.041175\n",
       "1      285383  0.322410  0.013904  0.094937  0.568750\n",
       "2      285384  0.419784  0.233136  0.227026  0.120054\n",
       "3      285385  0.287099  0.516503  0.118180  0.078218\n",
       "4      285386  0.377663  0.224787  0.331835  0.065715\n",
       "...       ...       ...       ...       ...       ...\n",
       "73030  358412  0.861071  0.081721  0.041671  0.015536\n",
       "73031  358413  0.335623  0.069149  0.587107  0.008120\n",
       "73032  358414  0.604119  0.100185  0.287817  0.007879\n",
       "73033  358415  0.573586  0.106984  0.297592  0.021839\n",
       "73034  358416  0.364558  0.148368  0.343405  0.143669\n",
       "\n",
       "[73035 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./FakeDeep_Attempt4_NeuralNet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNEcboXAHDpYYd97FWOW++h",
   "name": "Untitled"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
