{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "name": "fake-deep_project2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heathjohn62/CS155-Fake-Deep/blob/main/project2/get_UV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNN2aAch5ba-"
      },
      "source": [
        "# Miniproject 2: MovieLens\n",
        "Authors: Julia Sloan, Ayooluwa Odemuyiwa, Randall Pulido, John Heath"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GndylNW5bbT"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5WPppnf5bbV"
      },
      "source": [
        "# Step 1: \n",
        "Fill in these functions to train the SVD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn7Y63375bbV"
      },
      "source": [
        "def grad_U(Ui, Yij, Vj, reg, eta):\n",
        "    \"\"\"\n",
        "    Takes as input Ui (the ith row of U), a training point Yij, the column\n",
        "    vector Vj (jth column of V^T), reg (the regularization parameter lambda),\n",
        "    and eta (the learning rate).\n",
        "\n",
        "    Returns the gradient of the regularized loss function with\n",
        "    respect to Ui multiplied by eta.\n",
        "    \"\"\"\n",
        "    grad = reg * Ui - (Yij - np.dot(Ui.T, Vj)) * Vj\n",
        "    return eta * grad\n",
        "\n",
        "\n",
        "def grad_V(Vj, Yij, Ui, reg, eta):\n",
        "    \"\"\"\n",
        "    Takes as input the column vector Vj (jth column of V^T), a training point Yij,\n",
        "    Ui (the ith row of U), reg (the regularization parameter lambda),\n",
        "    and eta (the learning rate).\n",
        "\n",
        "    Returns the gradient of the regularized loss function with\n",
        "    respect to Vj multiplied by eta.\n",
        "    \"\"\"\n",
        "    grad = reg * Vj - (Yij - np.dot(Ui.T, Vj)) * Ui\n",
        "    return eta * grad\n",
        "\n",
        "def get_err(U, V, Y, reg=0.0):\n",
        "    \"\"\"\n",
        "    Takes as input a matrix Y of triples (i, j, Y_ij) where i is the index of a user,\n",
        "    j is the index of a movie, and Y_ij is user i's rating of movie j and\n",
        "    user/movie matrices U and V.\n",
        "\n",
        "    Returns the mean regularized squared-error of predictions made by\n",
        "    estimating Y_{ij} as the dot product of the ith row of U and the jth column of V^T.\n",
        "    \"\"\"\n",
        "    u_norm = np.linalg.norm(U)\n",
        "    v_norm = np.linalg.norm(V)\n",
        "    norms = (reg / 2.0) * ((u_norm ** 2) + (v_norm ** 2))\n",
        "\n",
        "    error = norms\n",
        "    for y in Y:\n",
        "        y_ij = y[2]\n",
        "        i = y[0] - 1\n",
        "        j = y[1] - 1\n",
        "\n",
        "        est = np.dot(U[i], V[j])\n",
        "        error += .5 * ((y_ij - est) ** 2)\n",
        "\n",
        "    return error / len(Y)\n",
        "\n",
        "\n",
        "def train_model(M, N, K, eta, reg, Y, eps=0.0001, max_epochs=300):\n",
        "    \"\"\"\n",
        "    Given a training data matrix Y containing rows (i, j, Y_ij)\n",
        "    where Y_ij is user i's rating on movie j, learns an\n",
        "    M x K matrix U and N x K matrix V such that rating Y_ij is approximated\n",
        "    by (UV^T)_ij.\n",
        "\n",
        "    Uses a learning rate of <eta> and regularization of <reg>. Stops after\n",
        "    <max_epochs> epochs, or once the magnitude of the decrease in regularized\n",
        "    MSE between epochs is smaller than a fraction <eps> of the decrease in\n",
        "    MSE after the first epoch.\n",
        "\n",
        "    Returns a tuple (U, V, err) consisting of U, V, and the unregularized MSE\n",
        "    of the model.\n",
        "    \"\"\"\n",
        "    # Initialize U and V to contain small random numbers between -.5 and .5\n",
        "    U = np.random.rand(M, K) - 0.5\n",
        "    V = np.random.rand(N, K) - 0.5\n",
        "\n",
        "    NUM_EPOCHS = 300\n",
        "    error0 = get_err(U, V, Y, reg)\n",
        "    prev_error = error0\n",
        "    error = prev_error + 5.0    \n",
        "    \n",
        "    # Loop over defined number of epochs\n",
        "    for n in range(NUM_EPOCHS):\n",
        "        # Loop over all points in Y randomly\n",
        "        indices = np.random.permutation(len(Y))\n",
        "        for m in indices:\n",
        "            i = Y[m][0] - 1\n",
        "            j = Y[m][1] - 1\n",
        "            y = Y[m][2]\n",
        "\n",
        "            U[i] -= grad_U(U[i], y, V[j], reg, eta)\n",
        "            V[j] -= grad_V(V[j], y, U[i], reg, eta)\n",
        "\n",
        "        \n",
        "        error = get_err(U, V, Y, reg)\n",
        "        if n == 0:\n",
        "            error1 = error\n",
        "\n",
        "        if ((np.abs(prev_error - error) / np.abs(error1 - error0)) <= eps):\n",
        "            return (U, V, prev_error)\n",
        "\n",
        "        prev_error = error\n",
        "\n",
        "    return (U, V, prev_error)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWDsXqwU5bbW"
      },
      "source": [
        "## 2D:\n",
        "Run the cell below to get your graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnnDfbwu5bbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb6976a2-df7e-433b-ac23-242d6afd9e33"
      },
      "source": [
        "# Data columns: User ID, Movie ID, Rating\n",
        "Y_train = np.loadtxt('https://raw.githubusercontent.com/lakigigar/Caltech-CS155-2021/main/projects/project2/data/train.txt').astype(int)\n",
        "Y_test = np.loadtxt('https://raw.githubusercontent.com/lakigigar/Caltech-CS155-2021/main/projects/project2/data/test.txt').astype(int)\n",
        "\n",
        "M = max(max(Y_train[:,0]), max(Y_test[:,0])).astype(int) # users\n",
        "N = max(max(Y_train[:,1]), max(Y_test[:,1])).astype(int) # movies\n",
        "print(\"Factorizing with \", M, \" users, \", N, \" movies.\")\n",
        "\n",
        "# Use k=20 as specified in project specs\n",
        "K = 20\n",
        "\n",
        "reg = 0.0\n",
        "eta = 0.03 # learning rate\n",
        "E_in = []\n",
        "E_out = []\n",
        "\n",
        "# Use to compute Ein and Eout\n",
        "U,V, err = train_model(M, N, K, eta, reg, Y_train)\n",
        "E_in = err\n",
        "E_out = get_err(U, V, Y_test)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Factorizing with  943  users,  1682  movies.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}