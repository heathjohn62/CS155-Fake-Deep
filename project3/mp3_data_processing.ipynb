{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mp3_data-processing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heathjohn62/CS155-Fake-Deep/blob/main/project3/mp3_data_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5c-x0rXtO-A"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Gd_KwdH0AMg"
      },
      "source": [
        "# Each LINE in dataset is a line in resulting dataframe (numbers included)\r\n",
        "# Removes punctuation\r\n",
        "# To access line i, use train_data[0][i] \r\n",
        "# train_data is a pandas DataFrame (2309 rows x 1 column)\r\n",
        "# Each sonnet has a number in the line before it begins\r\n",
        "\r\n",
        "def get_data_no_punc():\r\n",
        "    train_data = pd.read_csv('https://raw.githubusercontent.com/lakigigar/Caltech-CS155-2021/main/projects/project3/data/shakespeare.txt', delimiter='\\n', header=None)\r\n",
        "\r\n",
        "    punctuation = [',']\r\n",
        "    # Go through each line of dataframe\r\n",
        "    for i in range(len(train_data[0])):\r\n",
        "        \r\n",
        "        train_data[0][i] = train_data[0][i].replace(',', '')\r\n",
        "        train_data[0][i] = train_data[0][i].replace('.', '')\r\n",
        "        train_data[0][i] = train_data[0][i].replace('!', '')\r\n",
        "        train_data[0][i] = train_data[0][i].replace('?', '')\r\n",
        "        train_data[0][i] = train_data[0][i].replace(';', '')\r\n",
        "        train_data[0][i] = train_data[0][i].replace(':', '')\r\n",
        "        train_data[0][i] = train_data[0][i].replace('(', '')\r\n",
        "        train_data[0][i] = train_data[0][i].replace(')', '')\r\n",
        "        train_data[0][i] = train_data[0][i].replace('\\'', '') # remove apostrophe\r\n",
        "        # Remove leading and trailing zeros\r\n",
        "        train_data[0][i] = train_data[0][i].strip().lower()\r\n",
        "\r\n",
        "        # Convert line to array of strings\r\n",
        "        train_data[0][i] = train_data[0][i].split(' ')\r\n",
        "\r\n",
        "    return train_data"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWMljdc-hAGC"
      },
      "source": [
        "# Get syllable dictionary as dataframe\r\n",
        "def get_syl_dict():\r\n",
        "    # Split on NEW LINES\r\n",
        "    syllable_dict = pd.read_csv('https://raw.githubusercontent.com/lakigigar/Caltech-CS155-2021/main/projects/project3/data/Syllable_dictionary.txt', delimiter='\\n', header=None, names=['words'])\r\n",
        "\r\n",
        "\r\n",
        "    for i in range(len(syllable_dict['words'])):\r\n",
        "        temp = syllable_dict['words'][i].split(\" \", 1)[0]\r\n",
        "        # remove apostrophe from syllable dictionary words\r\n",
        "        syllable_dict['words'][i] = temp.replace('\\'', '')\r\n",
        "    return syllable_dict"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4g7o-N-EWprn"
      },
      "source": [
        "# Map each word to its ID (word_id_map) and each ID to its work (id_word_map)\r\n",
        "# Length of map: 3176 (excluding duplicate words when apostrophes removed)\r\n",
        "def get_word_id_map(dict):\r\n",
        "    word_id_map = {}\r\n",
        "    word_counter = 0\r\n",
        "    id_word_map = {}\r\n",
        "\r\n",
        "    for word in dict['words']:\r\n",
        "        # Fix indexing for duplicate words\r\n",
        "        if word in word_id_map:\r\n",
        "            word_counter -= 1\r\n",
        "        word_id_map[word] = word_counter\r\n",
        "        id_word_map[word_counter] = word\r\n",
        "        word_counter += 1\r\n",
        "\r\n",
        "    return word_id_map, id_word_map"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxAlugHJWsVd"
      },
      "source": [
        "# Map each word to all words that come after it\r\n",
        "def get_next_word_map(id_map, data):\r\n",
        "    next_word_map = {}\r\n",
        "    ind = 1\r\n",
        "\r\n",
        "    # Convert training data to 1D list\r\n",
        "    poems = data.values.flatten().tolist()\r\n",
        "    poems = sum(poems, [])\r\n",
        "\r\n",
        "\r\n",
        "    for word in poems[ind:]:\r\n",
        "        key = poems[ind - 1]\r\n",
        "\r\n",
        "        # Ensure neither word nor key are numbers (denoting new poem)\r\n",
        "        if (not word.isdigit()) and (not key.isdigit()):\r\n",
        "            key_id = id_map[key]\r\n",
        "            # Add key, word pair to map\r\n",
        "            if key_id in next_word_map:\r\n",
        "                next_word_map[key_id].append(id_map[word])\r\n",
        "            else:\r\n",
        "                next_word_map[key_id] = [id_map[word]]\r\n",
        "        ind += 1\r\n",
        "\r\n",
        "    return next_word_map"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4mEOLpHgsSR"
      },
      "source": [
        "# MAIN CODE - call methods to get desired dataset, dictionary, and maps\r\n",
        "# Training data with punctation removed, separated by lines\r\n",
        "train_data = get_data_no_punc()\r\n",
        "# Dictionary mapping words to their number of syllables\r\n",
        "syllable_dict = get_syl_dict()\r\n",
        "# Dictionary mapping words to their unique IDs\r\n",
        "word_id_map, id_word_map = get_word_id_map(syllable_dict)\r\n",
        "# Dictionary mapping words to \r\n",
        "next_word_map = get_next_word_map(word_id_map, train_data)"
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}